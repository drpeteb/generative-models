{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of generative modelling is to formulate a mathematical representation of a physical process. Ideally this mathematical representation would allow us to:\n",
    "<ul>\n",
    "<li>Generate samples which are representative of the real process</li>\n",
    "<li>Evaluate a probability measure for the real process</li>\n",
    "</ul>\n",
    "\n",
    "Suppose that the real physical process generates samples $x \\in \\mathcal{X}$, and has a measure with density $\\pi(x)$. Most of the time the true mechanics encapsulated by $\\pi(x)$ will be unmanagably complicated. For examples, if $\\mathcal{X}$ is the space of $M \\times N \\times 3$ colour images, and we want $\\pi(x)$ to represent \"natural images\", then wrapped up in the probability distribution is information about the optics and sensors of all possible cameras that might take the image, their possible locations, orientations and scene illumination, at all possible times. Constructing this model from first principles is impossible.\n",
    "\n",
    "So instead we take advantage of the fact that while the full mechanics of the process might be prohibitively complicated, sampling data from it is not. We can just get a bunch of cameras, and then travel the world taking pictures. Or, even more simply, we can just scrape images from the internet, exploiting an army of amateur photographers across the world.\n",
    "\n",
    "If we were to attempt to build a generative model for natural images from scratch, we would need to explicitly consider distributions over all sorts of nuisance variables. For example, should we use a uniform distribution over locations on the earth's surface? (Lots of ocean.) Or should we focus the probability mass where people are likely to take photos? (Lots of Eiffel Tower.) It depends on what, exactly, we want our probability model to quantify. Is it the probability that this image could be taken? Or the probability that it ends up in a photo albumn? If we just go and collect some pictures, then, for better or worse, this data defines the underlying process. On the plus side, this implicilty marginalises all those nuisance parameters. On the other hand, it makes it all too easy to forget about them all, which may lead to nasty surprises later on when we attempt to apply our model to data drawn from a different process. For example, if we trained a model on images from my facebook feed, it would probably only be able to generate pictures of peoples' dinners and babies.\n",
    "\n",
    "Rather than trying to explicitly capture all the intricasies of the real generative process, we will attempt to imitate it. To do this, we select a parameterized family of models, and then adjust the parameters so as to mimimize some measure of discrepancy between the output of the model and the output of the real process. That's all there is to it. The interesting parts of this are:\n",
    "<ul>\n",
    "<li>What should the parameterized family of models be?</li>\n",
    "<li>What should that \"measure of discrepancy\" be?</li>\n",
    "<li>How do we minimize it?</li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
